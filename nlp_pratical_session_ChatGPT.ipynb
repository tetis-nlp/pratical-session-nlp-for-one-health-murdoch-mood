{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1 style=\"text-align: center;\">NLP for One Health</H1>\n",
    "<h3 style=\"text-align: center;\">From BERT to ChatGPT</h3>\n",
    "\n",
    "|   |   |   |   |\n",
    "|---|---|---|---|\n",
    "| <img src=\"https://mood-h2020.eu/wp-content/uploads/2020/10/logo_Mood_texte-dessous_CMJN_vecto-300x136.jpg\" alt=\"mood\"/> | <img src=\"https://www.murdoch.edu.au/ResourcePackages/Murdoch2021/assets/dist/images/logo.svg\" alt=\"murdoch\" /> | <img src=\"https://www.umr-tetis.fr/images/logo-header-tetis.png\" alt=\"tetis\"/> | <img src=\"https://www.inrae.fr/themes/custom/inrae_socle/logo.svg\" alt=\"INRAE\" /> |\n",
    "\n",
    "Speakers:\n",
    "\n",
    "- **RÃ©my DECOUPES** - Research engineer UMR TETIS / INRAE\n",
    "- **Maguelonne TEISSEIRE** - Prof. UMR TETIS / INRAE\n",
    "\n",
    "------------------------\n",
    "# Chapter 2: ChatGPT\n",
    "[ChatGPT](https://chat.openai.com) is an AI chatbot developed by OpenAI. ChatGPT uses a generative language model called GPT-3.5 without subscription and GPT-4 for $20/month.\n",
    "\n",
    "## 2.1 Requirements\n",
    "As we are going to use ChatGPT through the [OpenAI API](https://platform.openai.com/), participants need to create a account in order to obtain an API key: [here](https://platform.openai.com/)\n",
    "\n",
    "+ Free access: 18$ will be credited for a short period of time and it would not be renewed.\n",
    "+ Or add a payment method\n",
    "\n",
    "Then let's begin with GPT-3.5-turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# installation\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_key = \"sk-...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list models\n",
    "models = openai.Model.list()\n",
    "\n",
    "for model in models.data:\n",
    "    print(f\"{model.id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print GPT3.5 info\n",
    "print(models.data[44])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo-0301\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an academic researcher\"},\n",
    "        {\"role\": \"user\", \"content\": \"Could you explain me what one health concept is ?\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(response['choices'][0]['message']['content'])\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Text generation with ChatGPT\n",
    "\n",
    "Let's now try the same text generation that we tried with BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_sentence = \"One Health is an approach calling for the collaborative efforts of multiple\"\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo-0301\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": f\"Could you complete this following sentence ? {my_sentence}\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_question = \"question: What does 'one health concept' mean ?\"\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo-0301\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": f\"Could you answer to this following question ? {my_question}\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ChatGPT can also do classical NLP tasks such as Name Entities Recognition**\n",
    "\n",
    "Same example that for BERT: \"2 swans found dead in Dordogne\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_sentence = \"2 swans found dead in Dordogne\"\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo-0301\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": f\"Do a Name Entity Recognition for the following sentence: '{my_sentence}'\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Langchain\n",
    "GPT-3.5 is not the only LLM ! Langchain is a python library that makes easy to use different API (like OpenAI, HuggingFace, Cohere, ...)\n",
    "\n",
    "From \"[A Survey of Large Language Models](http://arxiv.org/abs/2302.07842)\" - Zhao et al. - 2023:\n",
    "\n",
    "<img align=\"left\" src=https://gitlab.irstea.fr/umr-tetis/mood/pratical-session-nlp-for-one-health-murdoch-mood/-/raw/master/ressources/LLM_chronology>\n",
    "\n",
    "<img align=\"right\" src=\"https://huggingface.co/front/assets/huggingface_logo-noborder.svg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in ./.conda/lib/python3.10/site-packages (0.0.135)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in ./.conda/lib/python3.10/site-packages (from langchain) (0.5.7)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in ./.conda/lib/python3.10/site-packages (from langchain) (4.0.2)\n",
      "Requirement already satisfied: requests<3,>=2 in ./.conda/lib/python3.10/site-packages (from langchain) (2.28.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./.conda/lib/python3.10/site-packages (from langchain) (3.8.4)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in ./.conda/lib/python3.10/site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in ./.conda/lib/python3.10/site-packages (from langchain) (1.2.4)\n",
      "Requirement already satisfied: pydantic<2,>=1 in ./.conda/lib/python3.10/site-packages (from langchain) (1.10.7)\n",
      "Requirement already satisfied: numpy<2,>=1 in ./.conda/lib/python3.10/site-packages (from langchain) (1.23.5)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in ./.conda/lib/python3.10/site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: SQLAlchemy<2,>=1 in ./.conda/lib/python3.10/site-packages (from langchain) (1.4.47)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in ./.conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.1.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in ./.conda/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in ./.conda/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (1.5.1)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in ./.conda/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.8.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in ./.conda/lib/python3.10/site-packages (from pydantic<2,>=1->langchain) (4.5.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./.conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2022.12.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./.conda/lib/python3.10/site-packages (from SQLAlchemy<2,>=1->langchain) (2.0.2)\n",
      "Requirement already satisfied: packaging>=17.0 in ./.conda/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./.conda/lib/python3.10/site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n",
      "Requirement already satisfied: huggingface_hub in ./.conda/lib/python3.10/site-packages (0.13.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.conda/lib/python3.10/site-packages (from huggingface_hub) (6.0)\n",
      "Requirement already satisfied: requests in ./.conda/lib/python3.10/site-packages (from huggingface_hub) (2.28.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in ./.conda/lib/python3.10/site-packages (from huggingface_hub) (4.65.0)\n",
      "Requirement already satisfied: packaging>=20.9 in ./.conda/lib/python3.10/site-packages (from huggingface_hub) (23.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.conda/lib/python3.10/site-packages (from huggingface_hub) (4.5.0)\n",
      "Requirement already satisfied: filelock in ./.conda/lib/python3.10/site-packages (from huggingface_hub) (3.10.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./.conda/lib/python3.10/site-packages (from requests->huggingface_hub) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.conda/lib/python3.10/site-packages (from requests->huggingface_hub) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.conda/lib/python3.10/site-packages (from requests->huggingface_hub) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.conda/lib/python3.10/site-packages (from requests->huggingface_hub) (3.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain\n",
    "!pip install huggingface_hub"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 With HuggingFace API\n",
    "\n",
    "Same procedure as for OpenAI ChatGPT, we need a HuggingFace API key. Follow this link to have [instructions to get your HuggingFace API key](https://huggingface.co/docs/api-inference/quicktour#get-your-api-token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"hf_...\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Google Flan-T5-XL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import HuggingFaceHub\n",
    "\n",
    "llm = HuggingFaceHub(repo_id=\"google/flan-t5-xl\")\n",
    "\n",
    "llm(\"What does 'one health concept' mean ?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BigScience BLOOM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import HuggingFaceHub\n",
    "\n",
    "llm = HuggingFaceHub(repo_id=\"bigscience/bloom\")\n",
    "\n",
    "llm(\"What does 'one health concept' mean ?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 With ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    " \n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(model_name=\"gpt-3.5-turbo-0301\")\n",
    "\n",
    "llm(\"What does 'one health concept' mean ?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Hallucination\n",
    "LLMs have four main limitations:\n",
    "\n",
    "+ **Hallucination**: the generated text could be incorrect\n",
    "+ Continual learning: is too complexe. For example ChatGPT (GPT-3.5) has been trained on corpus until September 2021. Thus, this means that any information or events that have occured after September 2021 are not included in its knowledge base. \n",
    "+ Contextual size is limited: the processing text that ChatGPT (GPT-3.5) can take into account is limited at 2048 tokens.\n",
    "+ Ethical issues: Even if OpenAI provides ethical filters, the generated text could be toxic and could contain discriminating passages (racism, sexism, ...)\n",
    "\n",
    "In the frame of One-Health, let's focus on hallucination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(model_name=\"gpt-3.5-turbo-0301\")\n",
    "\n",
    "llm(\"Could you provide a bibliography dealing with One health concept in a scientific paper way ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Sure, here is a list of scientific papers related to the One Health concept:\\n\\n1. One Health: Interconnectedness of Human, Animal, and Environmental Health. Wolfe ND, Dunavan CP, Diamond J. Pediatr Infect Dis J. 2007 May;26(5):489-491. doi: 10.1097/INF.0b013e3180639e83.\\n\\n2. One Health: Challenges and Opportunities for a Holistic and Collaborative Approach to Health. Zinsstag J, Schelling E, Waltner-Toews D, Tanner M. Trans R Soc Trop Med Hyg. 2011 Sep;105(9):467-473. doi: 10.1016/j.trstmh.2011.04.010.\\n\\n3. One Health: From Concept to Action. Rabinowitz PM, Conti LA. Comp Immunol Microbiol Infect Dis. 2013 Nov;36(6):227-232. doi: 10.1016/j.cimid.2013.01.002.\\n\\n4. One Health: The Intersection of Human, Animal, and Environmental Health. Gibbs EPJ. Int J One Health. 2015;1:1-3. doi: 10.1111/tbed.12393.\\n\\n5. One Health: The Global Challenge of Epidemic Preparedness. Karesh WB, Dobson A, Lloyd-Smith JO, et al. Lancet Infect Dis. 2012 Feb;12(2):140-141. doi: 10.1016/S1473-3099(11)70304-2.\\n\\n6. The One Health Concept: 10 Years Old and a Long Road Ahead. RÃ¼egg SR, McMahon BJ, HÃ¤sler B, et al. Front Vet Sci. 2018 Jul 5;5:14. doi: 10.3389/fvets.2018.00014.\\n\\n7. One Health and the Neglected Tropical Diseases: The Interface of Humans, Animals, and the Environment. Hotez PJ, Bottazzi ME, Zhan B, et al. PLoS Negl Trop Dis. 2012 Dec;6(12):e1612. doi: 10.1371/journal.pntd.0001612.\\n\\n8. One Health: A New Professional Imperative. Kahn LH. Vet Ital. 2009 Oct-Dec;45(4):495-510. doi: 10.1111/tbed.12393.\\n\\n9. One Health: A Conceptual Framework for Health and Environment Policy. Franco C, Andrade M, da Silva JÃºnior AJ, et al. Environ Health Prev Med. 2014 Jul;19(4):324-327. doi: 10.1007/s12199-014-0398-3.\\n\\n10. One Health and Climate Change: An Emerging Public Health Policy Framework. Morse SS, Mazet JAK, Woolhouse M, et al. Trans R Soc Trop Med Hyg. 2012 Aug;106(8):451-457. doi: 10.1016/j.trstmh.2012.02.015.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try to accept to the DOI generated by ChatGPT:**\n",
    "\n",
    "For example for the last paper : https://doi.org/ + 10.1016/j.trstmh.2012.02.015 => [https://doi.org/10.1016/j.trstmh.2012.02.015] Leads to **DOI not found**\n",
    "\n",
    "ChatGPT has just created this reference "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Paper-QA\n",
    "To prevent hallucination, LLMs have to been grounded with real references.\n",
    "\n",
    "Paper-QA is a python library built uppon LangChain that allow to question and answer from our PDF papers. By grounding responses with in-text citations, it reduces hallucinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install paper-qa"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import your article files (in PDF format)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "see which files have been imported to your google session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(uploaded.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    " \n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paperqa import Docs\n",
    "\n",
    "my_docs = list(uploaded.keys())\n",
    "\n",
    "docs = Docs()\n",
    "for d in my_docs:\n",
    "    docs.add(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = docs.query(\"Could you list all environnement data that could have an impact on avian influenza outbreak ?\")\n",
    "print(answer.formatted_answer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How does paper-qa work ?**\n",
    "\n",
    "<img src=\"https://gitlab.irstea.fr/umr-tetis/mood/pratical-session-nlp-for-one-health-murdoch-mood/-/raw/master/ressources/paper-qa-explanations.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
